{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "try:\n",
    "    type(sc)\n",
    "except NameError:\n",
    "    sc = pyspark.SparkContext('local[*]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio:\n",
    "### El servicio meteorologico registra datos del tiempo para todas las ciudades donde posee una base de medicion.\n",
    "### Esta informacion se encuentra en 2 RDD.\n",
    "### En el primero se tiene informacion de las bases de medicion: (ID_BASE, NOMBRE, PCIA, CIUDAD, LAT, LON)\n",
    "### El segundo posee informacion sobre las mediciones en si: (TIMESTAMP, ID_BASE, TEMPERATURA, HUMEDAD, PRESION, DIRECCION_VIENTO, VELOCIDAD_VIENTO).\n",
    "### Se desea obtener un reporte para las bases de la Provincia de buenos Aires. El mismo debe informar los ID y nombre de bases de medicion que hayan registrado una variacion de temperatura promedio mensual mayor al 30% en el a√±o 2018 (dada la temperatura con el promedio del mes anterior, para determinar la variacion porcentual)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creo datos iniciales que luego voy a paralelizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Id_base, nombre, pcia, ciudad, lat, lon\n",
    "datos_bases = [(1,'basecita','bs.as','temp',10,10),\n",
    "              (2,'base2','bs.as','lom',10,10),\n",
    "              (3,'basecilla','bs.as','lan',10,10),\n",
    "              (4,'LA BASE','bs.as','cons',10,10),\n",
    "              (5,'basecita2','bs.as','ave',10,10),\n",
    "              (6,'base51','salta','salta',10,10)]\n",
    "\n",
    "#Timestamp, id_base, temperatura, humedad, presion, direccion_viento, velocidad_viento\n",
    "datos_medic = [('2017-12-11',1,19.5,99,1,'n',1000),\n",
    "               ('2017-12-11',2,19.5,99,1,'n',1000),\n",
    "               ('2017-12-11',3,100,99,1,'n',1000),\n",
    "               ('2017-12-11',4,19.5,99,1,'n',1000),\n",
    "               ('2017-12-11',5,19.5,99,1,'n',1000),\n",
    "               ('2016-05-11',2,19.5,99,1,'n',1000),\n",
    "               ('2016-05-11',3,100,99,1,'n',1000),\n",
    "               ('2016-05-11',4,19.5,99,1,'n',1000),\n",
    "               ('2016-05-11',5,19.5,99,1,'n',1000),\n",
    "               ('2016-05-11',1,19.5,99,1,'n',1000),\n",
    "               ('2018-01-11',1,19.5,99,1,'n',1000),\n",
    "               ('2018-01-11',2,21,99,1,'n',1000),\n",
    "               ('2018-01-11',3,100,99,1,'n',1000),\n",
    "               ('2018-02-11',3,100,99,1,'n',1000),\n",
    "               ('2018-01-11',4,4,99,1,'n',1000),\n",
    "               ('2018-01-11',5,12,99,1,'n',1000),\n",
    "               ('2018-02-11',1,123,99,1,'n',1000),\n",
    "               ('2018-02-11',2,13,99,1,'n',1000),\n",
    "               ('2018-02-11',3,100,99,1,'n',1000),\n",
    "               ('2018-02-11',4,5,99,1,'n',1000),\n",
    "               ('2018-02-11',5,28,99,1,'n',1000),\n",
    "               ('2018-02-11',1,9,99,1,'n',1000),\n",
    "               ('2018-02-11',2,1,99,1,'n',1000),\n",
    "               ('2018-02-11',3,100,99,1,'n',1000),\n",
    "               ('2018-02-11',4,127,99,1,'n',1000),\n",
    "               ('2018-02-11',5,14,99,1,'n',1000),\n",
    "               ('2018-03-11',1,1000,99,1,'n',1000),\n",
    "               ('2018-03-11',1,2,99,1,'n',1000),\n",
    "               ('2018-03-11',2,21,99,1,'n',1000),\n",
    "               ('2018-03-11',3,100,99,1,'n',1000),\n",
    "               ('2018-03-11',4,25,99,1,'n',1000),\n",
    "               ('2018-03-11',5,33,99,1,'n',1000),\n",
    "               ('2018-03-11',2,12,99,1,'n',1000),\n",
    "               ('2018-04-11',1,14,99,1,'n',1000),\n",
    "               ('2018-04-11',2,13,99,1,'n',1000),\n",
    "               ('2018-04-11',3,100,99,1,'n',1000),\n",
    "               ('2018-04-11',4,12,99,1,'n',1000),\n",
    "               ('2018-04-11',5,15,99,1,'n',1000),\n",
    "               ('2018-05-11',1,19,99,1,'n',1000),\n",
    "               ('2018-05-11',2,23,99,1,'n',1000),\n",
    "               ('2018-05-11',3,100,99,1,'n',1000),\n",
    "               ('2018-05-11',4,1,99,1,'n',1000),\n",
    "               ('2018-05-11',5,33,99,1,'n',1000),\n",
    "               ('2018-05-11',1,41,99,1,'n',1000),\n",
    "               ('2018-05-11',2,2,99,1,'n',1000),\n",
    "               ('2018-05-11',3,100,99,1,'n',1000),\n",
    "               ('2018-05-11',4,44,99,1,'n',1000),\n",
    "               ('2018-05-11',5,33,99,1,'n',1000),\n",
    "               ('2018-06-11',1,1,99,1,'n',1000),\n",
    "               ('2018-06-11',2,2,99,1,'n',1000),\n",
    "               ('2018-06-11',3,100,99,1,'n',1000),\n",
    "               ('2018-06-11',4,3,99,1,'n',1000),\n",
    "               ('2018-06-11',5,1,99,1,'n',1000),\n",
    "               ('2018-06-11',1,22,99,1,'n',1000),\n",
    "               ('2018-06-11',2,33,99,1,'n',1000),\n",
    "               ('2018-06-11',3,100,99,1,'n',1000),\n",
    "               ('2018-06-11',4,22,99,1,'n',1000),\n",
    "               ('2018-06-11',5,11,99,1,'n',1000),\n",
    "               ('2018-07-11',1,11,99,1,'n',1000),\n",
    "               ('2018-07-11',2,11,99,1,'n',1000),\n",
    "               ('2018-07-11',3,100,99,1,'n',1000),\n",
    "               ('2018-07-11',4,11,99,1,'n',1000),\n",
    "               ('2018-07-11',5,11,99,1,'n',1000),\n",
    "               ('2018-08-11',1,11,99,1,'n',1000),\n",
    "               ('2018-08-11',2,11,99,1,'n',1000),\n",
    "               ('2018-08-11',3,100,99,1,'n',1000),\n",
    "               ('2018-08-11',4,11,99,1,'n',1000),\n",
    "               ('2018-08-11',5,11,99,1,'n',1000),\n",
    "               ('2018-09-11',1,11,99,1,'n',1000),\n",
    "               ('2018-09-11',2,11,99,1,'n',1000),\n",
    "               ('2018-09-11',3,100,99,1,'n',1000),\n",
    "               ('2018-09-11',4,11,99,1,'n',1000),\n",
    "               ('2018-09-11',5,11,99,1,'n',1000),\n",
    "               ('2018-10-11',1,11,99,1,'n',1000),\n",
    "               ('2018-10-11',2,11,99,1,'n',1000),\n",
    "               ('2018-10-11',3,100,99,1,'n',1000),\n",
    "               ('2018-10-11',4,11,99,1,'n',1000),\n",
    "               ('2018-10-11',5,11,99,1,'n',1000),\n",
    "               ('2018-11-11',1,11,99,1,'n',1000),\n",
    "               ('2018-11-11',2,11,99,1,'n',1000),\n",
    "               ('2018-11-11',3,100,99,1,'n',1000),\n",
    "               ('2018-11-11',4,11,99,1,'n',1000),\n",
    "               ('2018-11-11',5,11,99,1,'n',1000),\n",
    "               ('2018-12-11',1,11,99,1,'n',1000),\n",
    "               ('2018-12-11',2,11,99,1,'n',1000),\n",
    "               ('2018-12-11',3,100,99,1,'n',1000),\n",
    "               ('2018-12-11',4,11,99,1,'n',1000),\n",
    "               ('2018-12-11',5,11,99,1,'n',1000)]\n",
    "len(datos_medic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_med=sc.parallelize(datos_medic)\n",
    "rdd_bas=sc.parallelize(datos_bases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algunas pruebas antes de hacer la solucion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtengo tuplas (Id base, lista mes y promedio temp) usando reduce by key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 45.3 ms, sys: 8.23 ms, total: 53.5 ms\n",
      "Wall time: 610 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(2,\n",
       "  [('2016-05-11', 19.5),\n",
       "   ('2018-04-11', 13.0),\n",
       "   ('2018-05-11', 12.5),\n",
       "   ('2018-06-11', 17.5),\n",
       "   ('2018-07-11', 11.0),\n",
       "   ('2018-10-11', 11.0),\n",
       "   ('2018-11-11', 11.0),\n",
       "   ('2018-12-11', 11.0),\n",
       "   ('2017-12-11', 19.5),\n",
       "   ('2018-01-11', 21.0),\n",
       "   ('2018-02-11', 7.0),\n",
       "   ('2018-03-11', 16.5),\n",
       "   ('2018-08-11', 11.0),\n",
       "   ('2018-09-11', 11.0)]),\n",
       " (4,\n",
       "  [('2016-05-11', 19.5),\n",
       "   ('2018-04-11', 12.0),\n",
       "   ('2018-05-11', 22.5),\n",
       "   ('2018-06-11', 12.5),\n",
       "   ('2018-07-11', 11.0),\n",
       "   ('2018-10-11', 11.0),\n",
       "   ('2018-11-11', 11.0),\n",
       "   ('2018-12-11', 11.0),\n",
       "   ('2017-12-11', 19.5),\n",
       "   ('2018-01-11', 4.0),\n",
       "   ('2018-02-11', 66.0),\n",
       "   ('2018-03-11', 25.0),\n",
       "   ('2018-08-11', 11.0),\n",
       "   ('2018-09-11', 11.0)]),\n",
       " (1,\n",
       "  [('2017-12-11', 19.5),\n",
       "   ('2018-01-11', 19.5),\n",
       "   ('2018-02-11', 66.0),\n",
       "   ('2018-03-11', 501.0),\n",
       "   ('2018-08-11', 11.0),\n",
       "   ('2018-09-11', 11.0),\n",
       "   ('2016-05-11', 19.5),\n",
       "   ('2018-04-11', 14.0),\n",
       "   ('2018-05-11', 30.0),\n",
       "   ('2018-06-11', 11.5),\n",
       "   ('2018-07-11', 11.0),\n",
       "   ('2018-10-11', 11.0),\n",
       "   ('2018-11-11', 11.0),\n",
       "   ('2018-12-11', 11.0)]),\n",
       " (3,\n",
       "  [('2017-12-11', 100.0),\n",
       "   ('2018-01-11', 100.0),\n",
       "   ('2018-02-11', 100.0),\n",
       "   ('2018-03-11', 100.0),\n",
       "   ('2018-08-11', 100.0),\n",
       "   ('2018-09-11', 100.0),\n",
       "   ('2016-05-11', 100.0),\n",
       "   ('2018-04-11', 100.0),\n",
       "   ('2018-05-11', 100.0),\n",
       "   ('2018-06-11', 100.0),\n",
       "   ('2018-07-11', 100.0),\n",
       "   ('2018-10-11', 100.0),\n",
       "   ('2018-11-11', 100.0),\n",
       "   ('2018-12-11', 100.0)]),\n",
       " (5,\n",
       "  [('2017-12-11', 19.5),\n",
       "   ('2018-01-11', 12.0),\n",
       "   ('2018-02-11', 21.0),\n",
       "   ('2018-03-11', 33.0),\n",
       "   ('2018-08-11', 11.0),\n",
       "   ('2018-09-11', 11.0),\n",
       "   ('2016-05-11', 19.5),\n",
       "   ('2018-04-11', 15.0),\n",
       "   ('2018-05-11', 33.0),\n",
       "   ('2018-06-11', 6.0),\n",
       "   ('2018-07-11', 11.0),\n",
       "   ('2018-10-11', 11.0),\n",
       "   ('2018-11-11', 11.0),\n",
       "   ('2018-12-11', 11.0)])]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "rdd_med.map(lambda x: ((x[1],x[0]),(x[2],1))).reduceByKey(lambda x,y: (x[0] + y[0],x[1] + y[1]))\\\n",
    "                    .map(lambda x: (x[0][0], [(x[0][1], x[1][0]/x[1][1])] ) )\\\n",
    "                    .reduceByKey(lambda x,y: x+y)\\\n",
    "                    .collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtengo tuplas (Id base, lista mes y promedio temp) usando group by key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 60.8 ms, sys: 4.01 ms, total: 64.9 ms\n",
      "Wall time: 665 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(2,\n",
       "  [('2016-05-11', 19.5),\n",
       "   ('2018-04-11', 13.0),\n",
       "   ('2018-05-11', 12.5),\n",
       "   ('2018-06-11', 17.5),\n",
       "   ('2018-07-11', 11.0),\n",
       "   ('2018-10-11', 11.0),\n",
       "   ('2018-11-11', 11.0),\n",
       "   ('2018-12-11', 11.0),\n",
       "   ('2017-12-11', 19.5),\n",
       "   ('2018-01-11', 21.0),\n",
       "   ('2018-02-11', 7.0),\n",
       "   ('2018-03-11', 16.5),\n",
       "   ('2018-08-11', 11.0),\n",
       "   ('2018-09-11', 11.0)]),\n",
       " (4,\n",
       "  [('2016-05-11', 19.5),\n",
       "   ('2018-04-11', 12.0),\n",
       "   ('2018-05-11', 22.5),\n",
       "   ('2018-06-11', 12.5),\n",
       "   ('2018-07-11', 11.0),\n",
       "   ('2018-10-11', 11.0),\n",
       "   ('2018-11-11', 11.0),\n",
       "   ('2018-12-11', 11.0),\n",
       "   ('2017-12-11', 19.5),\n",
       "   ('2018-01-11', 4.0),\n",
       "   ('2018-02-11', 66.0),\n",
       "   ('2018-03-11', 25.0),\n",
       "   ('2018-08-11', 11.0),\n",
       "   ('2018-09-11', 11.0)]),\n",
       " (1,\n",
       "  [('2017-12-11', 19.5),\n",
       "   ('2018-01-11', 19.5),\n",
       "   ('2018-02-11', 66.0),\n",
       "   ('2018-03-11', 501.0),\n",
       "   ('2018-08-11', 11.0),\n",
       "   ('2018-09-11', 11.0),\n",
       "   ('2016-05-11', 19.5),\n",
       "   ('2018-04-11', 14.0),\n",
       "   ('2018-05-11', 30.0),\n",
       "   ('2018-06-11', 11.5),\n",
       "   ('2018-07-11', 11.0),\n",
       "   ('2018-10-11', 11.0),\n",
       "   ('2018-11-11', 11.0),\n",
       "   ('2018-12-11', 11.0)]),\n",
       " (3,\n",
       "  [('2017-12-11', 100.0),\n",
       "   ('2018-01-11', 100.0),\n",
       "   ('2018-02-11', 100.0),\n",
       "   ('2018-03-11', 100.0),\n",
       "   ('2018-08-11', 100.0),\n",
       "   ('2018-09-11', 100.0),\n",
       "   ('2016-05-11', 100.0),\n",
       "   ('2018-04-11', 100.0),\n",
       "   ('2018-05-11', 100.0),\n",
       "   ('2018-06-11', 100.0),\n",
       "   ('2018-07-11', 100.0),\n",
       "   ('2018-10-11', 100.0),\n",
       "   ('2018-11-11', 100.0),\n",
       "   ('2018-12-11', 100.0)]),\n",
       " (5,\n",
       "  [('2017-12-11', 19.5),\n",
       "   ('2018-01-11', 12.0),\n",
       "   ('2018-02-11', 21.0),\n",
       "   ('2018-03-11', 33.0),\n",
       "   ('2018-08-11', 11.0),\n",
       "   ('2018-09-11', 11.0),\n",
       "   ('2016-05-11', 19.5),\n",
       "   ('2018-04-11', 15.0),\n",
       "   ('2018-05-11', 33.0),\n",
       "   ('2018-06-11', 6.0),\n",
       "   ('2018-07-11', 11.0),\n",
       "   ('2018-10-11', 11.0),\n",
       "   ('2018-11-11', 11.0),\n",
       "   ('2018-12-11', 11.0)])]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "## Si no hago mapValues(list) en este caso devuelve un iterable (y si no hago el mapValues entonces tarda m√°s\n",
    "## cuando hago el collect, supongo que el tipo de dato iterable debe ser m√°s pesado de levantar)\n",
    "rdd_med.map(lambda x: ((x[1],x[0]),(x[2],1))).reduceByKey(lambda x,y: (x[0] + y[0],x[1] + y[1]))\\\n",
    "                    .map(lambda x: (x[0][0], (x[0][1], x[1][0]/x[1][1]) ) )\\\n",
    "                    .groupByKey().mapValues(list)\\\n",
    "                    .collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prueba que hice para el ordenamiento de lista de tuplas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 3), (2, 3), (3, 5)]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def take_first(x):\n",
    "    return x[0]\n",
    "\n",
    "lista_tuplas = [(1,3),(3,5),(2,3)]\n",
    "\n",
    "sorted(lista_tuplas, key = take_first)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Veo que se obtiene el modulo de un numero usando ABS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=-1\n",
    "abs(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recuerdo el ejercicio para evitar scrollear hasta arriba:\n",
    "### El servicio meteorologico registra datos del tiempo para todas las ciudades donde posee una base de medicion.\n",
    "### Esta informacion se encuentra en 2 RDD.\n",
    "### En el primero se tiene informacion de las bases de medicion: (ID_BASE, NOMBRE, PCIA, CIUDAD, LAT, LON)\n",
    "### El segundo posee informacion sobre las mediciones en si: (TIMESTAMP, ID_BASE, TEMPERATURA, HUMEDAD, PRESION, DIRECCION_VIENTO, VELOCIDAD_VIENTO).\n",
    "### Se desea obtener un reporte para las bases de la Provincia de buenos Aires. El mismo debe informar los ID y nombre de bases de medicion que hayan registrado una variacion de temperatura promedio mensual mayor al 30% en el a√±o 2018 (dada la temperatura con el promedio del mes anterior, para determinar la variacion porcentual)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solucion del ejercicio: (Actualizada)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correccion a la solucion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 'basecita'), (5, 'basecita2'), (2, 'base2'), (4, 'LA BASE')]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def obtener_fecha(x):\n",
    "    fecha = x.split('-')\n",
    "    return (fecha[0] + '-' + fecha[1])\n",
    "    \n",
    "def tomar_primer_elemento(x):\n",
    "    return x[0]\n",
    "\n",
    "def hubo_dif_30_porciento(x):\n",
    "    lista_meses = sorted(list(x[1]), key=tomar_primer_elemento)\n",
    "    hubo_dif = False\n",
    "    for i in range(1,len(lista_meses)):\n",
    "        if ( (abs( (lista_meses[i][1] - lista_meses[i-1][1]) / (lista_meses[i-1][1]) ) > 0.3) ) :\n",
    "            hubo_dif = True\n",
    "    return hubo_dif\n",
    "\n",
    "\n",
    "rdd_bas_filt=rdd_bas.filter(lambda x: x[2] == 'bs.as').map(lambda x: (x[0],x[1]))\n",
    "\n",
    "\n",
    "rdd_med.filter(lambda x: ( x[0].split('-')[0] == '2018' ) | ((x[0].split('-')[0] == '2017') & (x[0].split('-')[1] == '12')))\\\n",
    "                    .map(lambda x: (x[1],(obtener_fecha(x[0]),x[2])))\\\n",
    "                    .join(rdd_bas_filt)\\\n",
    "                    .map(lambda x: ( (x[0],x[1][1],x[1][0][0]), (x[1][0][1],1)) )\\\n",
    "                    .reduceByKey(lambda x,y: (x[0] + y[0],x[1] + y[1]))\\\n",
    "                    .map(lambda x: ((x[0][0], x[0][1]), (x[0][2], x[1][0]/x[1][1]) ) )\\\n",
    "                    .groupByKey()\\\n",
    "                    .filter(hubo_dif_30_porciento)\\\n",
    "                    .map(lambda x: (x[0][0],x[0][1]))\\\n",
    "                    .collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtuve una lista de tuplas (id_base, nombre_base) con las bases que en alguno de los 12 meses registraron una diferencia superior al 30% con respecto al mes anterior en el promedio de temperatura (sin considerar enero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2017-12', '2017-12', '2017-12', '2017-12', '2017-12']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_med.map(lambda x: obtener_fecha(x[0])).take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
